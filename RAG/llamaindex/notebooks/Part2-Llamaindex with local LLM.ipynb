{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a3d6351-4a87-4e76-9db2-6ed8b7790c40",
   "metadata": {},
   "source": [
    "### save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ec1e96a-fb6e-4d66-a905-ed5f5dd077af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Writer/camel-5b-hf\")\n",
    "model = AutoModel.from_pretrained(\"Writer/camel-5b-hf\")\n",
    "\n",
    "tokenizer.save_pretrained(\"../models/camel-5b-hf\")\n",
    "model.save_pretrained(\"../models/camel-5b-hf\")\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-small-en-v1.5\")\n",
    "model = AutoModel.from_pretrained(\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "\n",
    "tokenizer.save_pretrained(\"../models/bge-small-en-v1.5\")\n",
    "model.save_pretrained(\"../models/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b1fc69-baa7-4f39-a3c0-2420280203e8",
   "metadata": {},
   "source": [
    "# load model: LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53a8ca6d-64ec-4311-a1cb-3dc3d12b7a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a549b2d28efe48148c6a691f8074dbfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "\n",
    "llm = HuggingFaceLLM(\n",
    "    tokenizer_name=\"../models/camel-5b-hf\",\n",
    "    model_name=\"../models/camel-5b-hf\",\n",
    "    context_window=2048,\n",
    "    max_new_tokens=512,\n",
    "    generate_kwargs={\"temperature\": 0.25, \"do_sample\": True},\n",
    "    device_map=\"auto\",\n",
    "    tokenizer_kwargs={\"max_length\": 2048},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc807fce-7b82-446d-a90c-a85b07108a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletionResponse(text='\\nMistral AI is an AI-driven weather forecasting system that provides real-time, accurate, and up-to-date weather forecasts for various regions worldwide.', additional_kwargs={}, raw={'model_output': tensor([[ 2061,   318, 15078,  1373,  9552,    30,   198, 49370,  1373,  9552,\n",
       "           318,   281,  9552,    12, 15808,  6193, 41164,  1080,   326,  3769,\n",
       "          1103,    12,  2435,    11,  7187,    11,   290,   510,    12,  1462,\n",
       "            12,  4475,  6193, 26119,   329,  2972,  7652,  8688,    13, 50256]],\n",
       "       device='cuda:0')}, delta=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.complete(\"What is Mistral AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bf94ecb-8326-4413-a483-8d3629fbccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"../models/bge-small-en-v1.5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8688d6ab-d207-4c3b-ba6f-87937b4a88cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.037243302911520004, -0.0008555697277188301, 0.08908320963382721]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = embed_model.get_text_embedding(\"머신 러닝은 재미있어요\")\n",
    "embeddings[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62264d38-2dc7-4d2b-841d-df9a685cfefd",
   "metadata": {},
   "source": [
    "# llamaindex from local model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1a5c49e-7284-40d1-937c-a1db5924e2b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "\n",
    "documents = SimpleDirectoryReader(\"../dataset/llamaindex_data\").load_data()\n",
    "vector_index = VectorStoreIndex.from_documents(documents, embed_model=embed_model, similarity_top_k=1)\n",
    "query_engine = vector_index.as_query_engine(llm=llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbbc2d8c-8b50-434d-800c-5c6c5daedc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "\n",
    "documents = SimpleDirectoryReader(\"../dataset/llamaindex_data\").load_data()\n",
    "\n",
    "vector_index = VectorStoreIndex.from_documents(documents, embed_model=\"local:../models/bge-small-en-v1.5\", similarity_top_k=1)\n",
    "query_engine = vector_index.as_query_engine(llm=llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc06b244-70d7-4805-b211-38b991d7fed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1508 > 512). Running this sequence through the model will result in indexing errors\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Mistral AI is a French company founded in April 2023, co-founded by Arthur Mensch, Guillaume Lample, and Timothée Lacroix. The company produces open-source large language models, including Mistral 7B, Mixtral 8x7B, and Mistral Medium. The company also sells AI-powered multilingual conversation assistants, known as \"Le Chat\". The company\\'s language processing model, Mistral 7B, has 7 billion parameters, while the \"instruct\" model has 7.3 billion parameters. The company also sells AI-powered multilingual conversation assistants, known as \"Le Chat\".'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = query_engine.query(\"What is Mistral AI?\")\n",
    "response.response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeec3407-fa4c-486c-aefa-29d58bb02060",
   "metadata": {},
   "source": [
    "# LLM QA system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30e5221-fd48-4ee6-b902-4653f004e473",
   "metadata": {},
   "source": [
    "## generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f2f865f-7d6f-475b-9548-df42ffc10501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sk-...'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "api_key = \"sk-...\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1efb108-2c89-433b-bc49-cd09b9077478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_wikipedia_page_links(title):\n",
    "    S = requests.Session()\n",
    "\n",
    "    URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"titles\": title,\n",
    "        \"prop\": \"links\",\n",
    "        \"pllimit\": \"max\"\n",
    "    }\n",
    "\n",
    "    all_links = []\n",
    "\n",
    "    while True:\n",
    "        response = S.get(url=URL, params=params).json()\n",
    "        pages = response.get('query', {}).get('pages', {})\n",
    "        for page_id, page_content in pages.items():\n",
    "            links = page_content.get('links', [])\n",
    "            for link in links:\n",
    "                all_links.append(link['title'])\n",
    "\n",
    "        if 'continue' in response:\n",
    "            params['plcontinue'] = response['continue']['plcontinue']\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return all_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c12679-26a1-4862-af75-908f6a93f9e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_lm = get_wikipedia_page_links('Large language model')\n",
    "len(links_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0fc737a-d002-4b20-a969-2056dab9c6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def get_response(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt},],\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d1f69a5-ae27-433b-9ce6-e15b6512bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_abstract(title):\n",
    "    response = requests.get(\n",
    "        \"https://en.wikipedia.org/w/api.php\",\n",
    "        params={\n",
    "            \"action\": \"query\",\n",
    "            \"format\": \"json\",\n",
    "            \"titles\": title,\n",
    "            \"prop\": \"extracts\",\n",
    "            \"exintro\": True,\n",
    "            \"explaintext\": True,\n",
    "        },\n",
    "    ).json()\n",
    "    page = next(iter(response['query']['pages'].values()))\n",
    "    return page.get(\"extract\", \"\")\n",
    "\n",
    "\n",
    "\n",
    "def is_ml_related(title, abstract):\n",
    "    prompt = f\"\"\"\n",
    "    Given the abstract of the Wikipedia article, determine if the article is machine-learning or language model related.\n",
    "    [Rules]\n",
    "    - Exclude articles about specific individuals\n",
    "    - Exclude articles that are about general knowledge and not related to machine-learning or langauge model.\n",
    "    - Include articles about the developer, company.\n",
    "    - Answer True if the article is related to machine-learning or language model, else False\n",
    "\n",
    "    [title]\n",
    "    {title}\n",
    "    [abstract]\n",
    "    {abstract}\n",
    "    [answer]\n",
    "    \"\"\"\n",
    "\n",
    "    return (get_response(prompt).lower().find(\"true\") > -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af6381d7-b001-44c4-a1e8-2212f8015a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI-complete'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "links_lm[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f44a094-3d94-450a-84eb-27a65cb368ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = links_lm[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b079210-e877-4334-85a7-86ac0adfc8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the field of artificial intelligence, the most difficult problems are informally known as AI-complete or AI-hard, implying that the difficulty of these computational problems, assuming intelligence is computational, is equivalent to that of solving the central artificial intelligence problem—making computers as intelligent as people, or strong AI.  To call a problem AI-complete reflects an attitude that it would not be solved by a simple specific algorithm.  \\nAI-complete problems are hypothesised to include computer vision, natural language understanding, and dealing with unexpected circumstances while solving any real-world problem.Currently, AI-complete problems cannot be solved with modern computer technology alone, but would also require human computation.  This property could be useful, for example, to test for the presence of humans as CAPTCHAs aim to do, and for computer security to circumvent brute-force attacks.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract = get_article_abstract(title)\n",
    "abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f869cdf6-c5fd-4b9c-9c89-f6afaa9a2550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_ml_related(title, abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf66d45c-35d6-4db0-8206-33e11742836c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The International Standard Book Number (ISBN) is a numeric commercial book identifier that is intended to be unique. Publishers purchase or receive ISBNs from an affiliate of the International ISBN Agency.An ISBN is assigned to each separate edition and variation (except reprintings) of a publication. For example, an e-book, a paperback and a hardcover edition of the same book must each have a different ISBN. The ISBN is ten digits long if assigned before 2007, and thirteen digits long if assigned on or after 1 January 2007. The method of assigning an ISBN is nation-specific and varies between countries, often depending on how large the publishing industry is within a country.\\nThe initial ISBN identification format was devised in 1967, based upon the 9-digit Standard Book Numbering (SBN) created in 1966. The 10-digit ISBN format was developed by the International Organization for Standardization (ISO) and was published in 1970 as international standard ISO 2108 (the 9-digit SBN code can be converted to a 10-digit ISBN by prefixing it with a zero).\\nPrivately published books sometimes appear without an ISBN. The International ISBN Agency sometimes assigns such books ISBNs on its own initiative.Another identifier, the International Standard Serial Number (ISSN), identifies periodical publications such as magazines and newspapers. The International Standard Music Number (ISMN) covers musical scores.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = \"ISBN\"\n",
    "abstract = get_article_abstract(title)\n",
    "abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb978da8-ff6f-43db-a9ad-4787c508700b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_ml_related(title, abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932640aa-6225-40fe-84ee-04d46025021e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2920e522-fabf-4acb-8d95-71cb09be00d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20332247-e0bb-432f-b8ec-9ad5d9b8e5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8e08ef-23fb-4718-8c35-05a880bab51e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d8c7439-5b7b-4508-99f3-1192a61d168a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"../dataset/lm_texts\")\n",
    "\n",
    "if not data_path.exists():\n",
    "    Path.mkdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b8a2c87-b1d3-4843-9787-60809f9b548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_full_article(title):\n",
    "    response = requests.get(\n",
    "        \"https://en.wikipedia.org/w/api.php\",\n",
    "        params={\n",
    "            \"action\": \"query\",\n",
    "            \"format\": \"json\",\n",
    "            \"titles\": title,\n",
    "            \"prop\": \"extracts\",\n",
    "            \"explaintext\": True,\n",
    "        },\n",
    "    ).json()\n",
    "    page = next(iter(response['query']['pages'].values()))\n",
    "    full_text = page.get(\"extract\", \"\")\n",
    "    \n",
    "    with open(f\"../dataset/lm_texts/{title}.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f37f12e-ce2b-4bba-bc79-5c13a7b6f2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_valid = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb083da6-4e5a-4dfd-9a49-72a1f672be27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 강의 현장 진행을 위한 tmp code\n",
    "def is_ml_related(title, abstract):\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9acd082-8d51-4edd-8212-39fe881c26e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 400/400 [01:03<00:00,  6.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for title in tqdm(links_lm):\n",
    "    abstract = get_article_abstract(title)\n",
    "    if is_ml_related(title, abstract):\n",
    "        save_full_article(title)\n",
    "        title_valid.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70c6f16b-632e-44f5-91b3-193c584262c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e060bb6-051f-49c1-a345-72b893989eb1",
   "metadata": {},
   "source": [
    "## setting llamaindex pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb2a8cfa-9bf5-4122-8807-965e8d77d978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings \n",
    "\n",
    "Settings.chunk_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "587bef15-f784-44a3-a97c-aa6be2749015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 46s, sys: 9.49 s, total: 2min 56s\n",
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "\n",
    "documents_lm = SimpleDirectoryReader(\"../dataset/lm_texts\").load_data()\n",
    "vector_index_lm = VectorStoreIndex.from_documents(documents_lm, embed_model=\"local:../models/bge-small-en-v1.5\", similarity_top_k=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6f4f6f-cbef-4790-a61b-a59a06b0fbd9",
   "metadata": {},
   "source": [
    "### saving vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "add16886-2dc2-4dbe-a41b-2180f9213e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index_lm.storage_context.persist(persist_dir=\"../models/vector_index_lm_text_bge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eaf329-c798-4f97-9420-902a85a00c71",
   "metadata": {},
   "source": [
    "#### loading vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74f4c742-ae4f-44b5-ada0-4a02baf83c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"../models/vector_index_lm_text_bge\")\n",
    "\n",
    "vector_index_lm = load_index_from_storage(storage_context, embed_model=\"local:../models/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "62ceaa02-b38e-4470-a680-856f061ef5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_lm = vector_index_lm.as_query_engine(llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac4c290-2580-4ec4-a109-02f74c70e127",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "## Evaluate - manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23005db7-68c9-4123-8ead-912b7f51ee39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TD learning is a teaching method that involves teaching a subject through a series of tasks or exercises, rather than using a textbook. It emphasizes active learning, self-directed learning, and the development of practical skills.\n",
      "========\n",
      "\n",
      "TD (TensorFlow Dynamic) learning is a type of machine learning algorithm used in supervised learning, where the goal is to learn a mapping from input to output by iteratively adjusting the weights of a neural network. It is particularly useful for tasks like classification and regression, where the output is continuous and can take any value.\n",
      "===Sources====\n",
      "Node ID: f9207060-01d3-4dc6-8834-9185e974dee6\n",
      "Text: OpenAI stated that full version of GPT-3 contains 175 billion\n",
      "parameters, two orders of magnitude larger than the 1.5 billion\n",
      "parameters in the full version of GPT-2 (although GPT-3 models with as\n",
      "few as 125 million parameters were also trained).OpenAI stated that\n",
      "GPT-3 succeeds at certain \"meta-learning\" tasks. It can generalize the\n",
      "purpose of ...\n",
      "Score:  0.622\n",
      "\n",
      "Node ID: c97490ff-e7f3-44fb-b40b-6c04fbcd86ca\n",
      "Text: OpenAI stated that full version of GPT-3 contains 175 billion\n",
      "parameters, two orders of magnitude larger than the 1.5 billion\n",
      "parameters in the full version of GPT-2 (although GPT-3 models with as\n",
      "few as 125 million parameters were also trained).OpenAI stated that\n",
      "GPT-3 succeeds at certain \"meta-learning\" tasks. It can generalize the\n",
      "purpose of ...\n",
      "Score:  0.617\n",
      "\n",
      "=====\n",
      "\n",
      "\n",
      "========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TD learning is a model-free reinforcement learning algorithm that learns by adjusting predictions based on current estimates, like dynamic programming methods, using bootstrapping.\n",
      "===Sources====\n",
      "Node ID: 290ca16a-84b0-4d39-b58c-63ed4aae00ef\n",
      "Text: Temporal difference (TD) learning refers to a class of model-\n",
      "free reinforcement learning methods which learn by bootstrapping from\n",
      "the current estimate of the value function. These methods sample from\n",
      "the environment, like Monte Carlo methods, and perform updates based\n",
      "on current estimates, like dynamic programming methods.While Monte\n",
      "Carlo meth...\n",
      "Score:  0.789\n",
      "\n",
      "Node ID: 89782e35-669d-4e30-b205-84623ab89781\n",
      "Text: S_{t+1}}    are the current and next states, respectively. The\n",
      "value                                    R                        t\n",
      "+             1                             +         γ         V\n",
      "(                    S                        t             +\n",
      "1                             )                 {\\displa...\n",
      "Score:  0.773\n",
      "\n",
      "=====\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is TD learning?\"\n",
    "\n",
    "print(llm.complete(query))\n",
    "\n",
    "for engine in [query_engine, query_engine_lm]:\n",
    "    print(\"========\")\n",
    "    response = engine.query(query)\n",
    "    \n",
    "    resp_text = response.response\n",
    "    resp_nodes = response.source_nodes\n",
    "    \n",
    "    print(resp_text)\n",
    "    print(\"===Sources====\")\n",
    "    for node in resp_nodes:\n",
    "        print(node)\n",
    "    print(\"=====\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f1bd3140-8a11-45dc-a8c6-d72f1619ee4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Claude3 is a French term for \"classical\" or \"high\" art, referring to works created during the Classical era (around the 16th-19th centuries) in Europe.\n",
      "========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sora, a text-to-video model, can generate high-quality videos up to one minute long. It uses a 12-billion-parameter GPT-3 model to interpret natural language inputs and generate corresponding images. OpenAI trained the system using publicly-available videos as well as copyrighted videos licensed for the purpose. The technology behind Sora is an adaptation of the DALL·E 3 text-to-image model. OpenAI demonstrated a few high-quality videos to the general public on February 15, 2024, stating that the technology was able to generate videos up to one minute long. It also shared a technical report highlighting the methods used to train the model and the model's capabilities. It acknowledged some shortcomings of the system, including struggles in simulating complex physics. Will Douglas Heaven of the MIT Technology Review called the demonstration videos \"impressive\", but noted that they must have been cherry-picked and may not be representative of Sora's typical output.\n",
      "===Sources====\n",
      "Node ID: ab5ba377-f700-4605-9f0a-35e6d727db4e\n",
      "Text: 3/11/24, 2:59 AM Mistral AI - Wikipedia\n",
      "https://en.wikipedia.org/wiki/Mistral_AI 4/58. \"Open-weight models and\n",
      "Mistral AI Large Language Models\"  (https://docs.mistral.ai/models/) .\n",
      "docs.mistral.ai . Retrieved 2024-01-04 . 9. \"Endpoints and Mistral AI\n",
      "Large Language Models\"  (https://docs.mistral.ai/platform/endpoints/#\n",
      "medium) . docs.mistral.ai...\n",
      "Score:  0.546\n",
      "\n",
      "Node ID: 028bf7bb-f83a-4244-a6c0-383690bfd1dc\n",
      "Text: ==== Codex ====  Announced in mid-2021, Codex is a descendant of\n",
      "GPT-3 that has additionally been trained on code from 54 million\n",
      "GitHub repositories, and is the AI powering the code autocompletion\n",
      "tool GitHub Copilot. In August 2021, an API was released in private\n",
      "beta. According to OpenAI, the model can create working code in over a\n",
      "dozen prog...\n",
      "Score:  0.545\n",
      "\n",
      "=====\n",
      "\n",
      "\n",
      "========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Claude 3 is a language model developed by Anthropic that was released in March 4, 2024. It is known for its ability to perform meta-cognitive reasoning, such as recognizing it is being tested during needle in a haystack tasks.\n",
      "===Sources====\n",
      "Node ID: 09d7ccc3-8ae0-4f2a-8397-7888eb501c42\n",
      "Text: === Claude 2 === Claude 2 was the next major iteration of\n",
      "Claude, which was released in July 11 2023 and available to the\n",
      "general public, whereas the Claude 1 was only available to selected\n",
      "users approved by Anthropic.Claude 2 expanded its context window from\n",
      "9,000 tokens to 100,000 tokens. Features included ability to upload\n",
      "PDFs and other docu...\n",
      "Score:  0.786\n",
      "\n",
      "Node ID: d4bda3a7-d3b3-4a78-b364-2beb87d9c053\n",
      "Text: === Claude 3 === Claude 3 was released on March 4, 2024 with\n",
      "claims in the press release to have set new industry benchmarks across\n",
      "a wide range of cognitive tasks. The Claude 3 family includes three\n",
      "state-of-the-art models in ascending order of capability: Haiku,\n",
      "Sonnet, and Opus. The default version of Claude 3 Opus has a context\n",
      "window of 200...\n",
      "Score:  0.769\n",
      "\n",
      "=====\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Claude3?\"\n",
    "\n",
    "print(llm.complete(query))\n",
    "\n",
    "for engine in [query_engine, query_engine_lm]:\n",
    "    print(\"========\")\n",
    "    response = engine.query(query)\n",
    "    \n",
    "    resp_text = response.response\n",
    "    resp_nodes = response.source_nodes\n",
    "    \n",
    "    print(resp_text)\n",
    "    print(\"===Sources====\")\n",
    "    for node in resp_nodes:\n",
    "        print(node)\n",
    "    print(\"=====\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704a7f69-af72-4775-a3e0-e6a21fea2bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3582ab3a-362a-421f-be97-63b501af8bf0",
   "metadata": {},
   "source": [
    "## Evaluate- using GPT call\n",
    "### Generate query from chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f15fca1-e328-4132-90b0-489ee9824265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "nodes = list(vector_index_lm.docstore.docs.values())\n",
    "nodes_sampled = [node.text for node in random.sample(nodes, 800)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4f0085f-2278-41cf-a5af-1b2d254ed119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_qa(context):\n",
    "    prompt = f\"\"\"\n",
    "    Given the context, generate the question-answer set\n",
    "    \n",
    "    [Rules]\n",
    "    - The question and answer must be sufficiently related.\n",
    "    - The question should be answerable by referring to the content of the context\n",
    "    - The question must be in one sentence.\n",
    "    - The answer must be three sentences or fewer.\n",
    "    \n",
    "    [Example A]\n",
    "    [context]\n",
    "    Perplexity\n",
    "    The most commonly used measure of a language model's performance is its perplexity on a given text corpus. Perplexity is a measure of how well a model is able to predict the contents of a dataset; the higher the likelihood the model assigns to the dataset, the lower the perplexity. Mathematically, perplexity is defined as the exponential of the average negative log likelihood per token:\n",
    "    Because language models may overfit to their training data, models are usually evaluated by their perplexity on a test set of unseen data.[38] This presents particular challenges for the evaluation of large language models. As they are trained on increasingly large corpora of text largely scraped from the web, it becomes increasingly likely that models' training data inadvertently includes portions of any given test set.[6\n",
    "    \n",
    "    [question]\n",
    "    What is perplexity?\n",
    "    \n",
    "    [answer]\n",
    "    Perplexity is a metric for assessing how effectively a language model can forecast the contents of a dataset, commonly used as a measure of a language model's\n",
    "    \n",
    "    \n",
    "    [Task]\n",
    "    [context]\n",
    "    {context}\n",
    "    [question]\n",
    "    \"\"\"\n",
    "\n",
    "    return get_response(prompt)\n",
    "\n",
    "\n",
    "def parse_qa(qa):\n",
    "    question, answer = qa.split(\"[answer]\")\n",
    "    question = question.strip()\n",
    "    answer = answer.strip()\n",
    "\n",
    "    return question, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99bccef0-46a0-4755-abd7-abf707891334",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = nodes[0]\n",
    "qa = gen_qa(context)\n",
    "q, a = parse_qa(qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95339d7-2820-4e6a-89b5-04d147539023",
   "metadata": {},
   "outputs": [],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "553dc9e0-da6d-41ba-bc94-dd4a4e9c764d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What do the terms AI-complete or AI-hard refer to in the field of artificial intelligence? \\n\\n[answer]\\nIn the field of artificial intelligence, the terms AI-complete or AI-hard refer to the most challenging computational problems, suggesting that solving these problems is equivalent in difficulty to making computers as intelligent as humans.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "12d07d7b-dad5-43c5-9cd1-d445923231f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What do the terms AI-complete or AI-hard refer to in the field of artificial intelligence?',\n",
       " 'In the field of artificial intelligence, the terms AI-complete or AI-hard refer to the most challenging computational problems, suggesting that solving these problems is equivalent in difficulty to making computers as intelligent as humans.')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21dc3ac5-cb8f-44ec-a3fc-7a43d6cb2dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "qa_pairs = []\n",
    "questions = []\n",
    "answers = []\n",
    "contexts = []\n",
    "for node in tqdm(nodes_sampled[:]):\n",
    "    pass\n",
    "    qa = gen_qa(node)\n",
    "    try:\n",
    "        q, a = parse_qa(qa)\n",
    "\n",
    "        contexts.append(node)\n",
    "        qa_pairs.append(qa)\n",
    "        questions.append(q)\n",
    "        answers.append(a)\n",
    "    except Exception as exp:\n",
    "        print(exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154f1460-9264-43ba-ad56-f64cfbb9b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa = pd.DataFrame({'context': contexts, 'qa_pairs': qa_pairs, 'question': questions, 'answer': answers})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "916b9cca-a8fc-4f62-b9f2-93171f8afe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa = pd.read_csv(\"../dataset/ml_qa_raw.csv\")\n",
    "df_qa[:20].to_csv(\"../dataset/ml_qa_test.csv\", index=False)\n",
    "df_qa[20:].to_csv(\"../dataset/ml_qa_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393bcab6-53a9-4bdc-8308-0467d6103a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d40a665-598c-4000-b170-41370e3cd086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11432869-798d-46f6-b2a5-d5765057c376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911910eb-579f-4fe5-8d12-fb1d4cc7096c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ed6235e-cc74-426a-9c0a-72bf1e5a64d4",
   "metadata": {},
   "source": [
    "### Generate query from selected models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19b14862-cf83-4cbc-9def-c1de2351a24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_models = [\"Claude 3\", \"Gemini 1.5\", \"Mixtral8x7B\", \"Llama2\", \"PanGu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7de771c4-e0b5-4dc4-b90f-cddbb788d4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"../dataset/lm_texts\").load_data()\n",
    "\n",
    "vector_index = VectorStoreIndex.from_documents(documents)\n",
    "vector_index.storage_context.persist(persist_dir=\"../models/vector_index_lm_text_chatGPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e8fd3bd-0c4a-40f8-bcfc-16ec3fddebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "01252349-83b3-42a3-af41-3c9d7215304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_contexts = []\n",
    "for model in new_models:\n",
    "    result = retriever.retrieve(model)[0].text\n",
    "    model_contexts.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420dcc1b-1f38-428e-b875-a06886f5e4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "08e3f2f9-6e38-49d8-8430-915097a3c08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_qa_new_models(context, model):\n",
    "    prompt = f\"\"\"\n",
    "    Given the context and model, generate the question-answer set\n",
    "    \n",
    "    [Rules]\n",
    "    - Generate questions about the model, and create answers to them based on the given context.\n",
    "    - Create a simple one-sentence question focusing on one aspect of the model's characteristics.\n",
    "    - Keep the answer to no more than two sentences.\n",
    "    \n",
    "    [Example A]\n",
    "    [context]\n",
    "    GPT-J or GPT-J-6B is an open-source large language model (LLM) developed by EleutherAI in 2021.[1] As the name suggests, it is a generative pre-trained transformer model designed to produce human-like text that continues from a prompt. The optional \"6B\" in the name refers to the fact that it has 6 billion parameters.[2]\n",
    "    [question]\n",
    "    When is the initial relase of GPT-J?\n",
    "    \n",
    "    [answer]\n",
    "    The initial release of GPT-J, an open-source large language model developed by EleutherAI, was in June 2021.\n",
    "    \n",
    "    [Task]\n",
    "    [context]\n",
    "    {context}\n",
    "    [model]\n",
    "    {model}\n",
    "    [question]\n",
    "    \"\"\"\n",
    "\n",
    "    return get_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7fe230dc-d7f8-4340-bbae-337a27b9f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pairs = []\n",
    "questions = []\n",
    "answers = []\n",
    "contexts = []\n",
    "for model, context in zip(new_models, model_contexts):\n",
    "    qa = gen_qa_new_models(model, context)\n",
    "    try:\n",
    "        q, a = parse_qa(qa)\n",
    "    \n",
    "        contexts.append(context)\n",
    "        qa_pairs.append(qa)\n",
    "        questions.append(q)\n",
    "        answers.append(a)\n",
    "    except Exception as exp:\n",
    "        pritn(exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ee05e4-fcbe-4290-bcad-50ad554c00ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa_new_model = pd.DataFrame({'context': contexts, 'qa_pairs': qa_pairs, 'question': questions, 'answer': answers})\n",
    "df_qa_new_model.to_csv(\"../dataset/ml_qa_new_models.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a471e989-077d-48b6-84c0-059f905b323c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>qa_pairs</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Claude is a family of large language models de...</td>\n",
       "      <td>What is Claude 3?\\n    \\n    [answer]\\n    Cla...</td>\n",
       "      <td>What is Claude 3?</td>\n",
       "      <td>Claude 3 is a software application used for de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>== Technical specifications ==\\nThe first gene...</td>\n",
       "      <td>What is the latest version of Gemini? \\n    \\n...</td>\n",
       "      <td>What is the latest version of Gemini?</td>\n",
       "      <td>The latest version of Gemini is 1.5.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>==== Mixtral 8x7B ====\\nMuch like Mistral's fi...</td>\n",
       "      <td>What is the key feature of Mixtral8x7B?\\n    \\...</td>\n",
       "      <td>What is the key feature of Mixtral8x7B?</td>\n",
       "      <td>Mixtral8x7B is known for its 7 billion paramet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>=== Fine-tuning ===\\nLlama 1 models are only a...</td>\n",
       "      <td>What is the purpose of Llama2?\\n\\n[answer]\\nLl...</td>\n",
       "      <td>What is the purpose of Llama2?</td>\n",
       "      <td>Llama2 is a language model designed to generat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Huawei PanGu, PanGu, PanGu-Σ or PanGu-π is a m...</td>\n",
       "      <td>What is PanGu? \\n    \\n[answer]\\nPanGu is a Ch...</td>\n",
       "      <td>What is PanGu?</td>\n",
       "      <td>PanGu is a Chinese natural language processing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Claude is a family of large language models de...   \n",
       "1  == Technical specifications ==\\nThe first gene...   \n",
       "2  ==== Mixtral 8x7B ====\\nMuch like Mistral's fi...   \n",
       "3  === Fine-tuning ===\\nLlama 1 models are only a...   \n",
       "4  Huawei PanGu, PanGu, PanGu-Σ or PanGu-π is a m...   \n",
       "\n",
       "                                            qa_pairs  \\\n",
       "0  What is Claude 3?\\n    \\n    [answer]\\n    Cla...   \n",
       "1  What is the latest version of Gemini? \\n    \\n...   \n",
       "2  What is the key feature of Mixtral8x7B?\\n    \\...   \n",
       "3  What is the purpose of Llama2?\\n\\n[answer]\\nLl...   \n",
       "4  What is PanGu? \\n    \\n[answer]\\nPanGu is a Ch...   \n",
       "\n",
       "                                  question  \\\n",
       "0                        What is Claude 3?   \n",
       "1    What is the latest version of Gemini?   \n",
       "2  What is the key feature of Mixtral8x7B?   \n",
       "3           What is the purpose of Llama2?   \n",
       "4                           What is PanGu?   \n",
       "\n",
       "                                              answer  \n",
       "0  Claude 3 is a software application used for de...  \n",
       "1               The latest version of Gemini is 1.5.  \n",
       "2  Mixtral8x7B is known for its 7 billion paramet...  \n",
       "3  Llama2 is a language model designed to generat...  \n",
       "4  PanGu is a Chinese natural language processing...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qa_new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f313c951-52ce-4f4c-b9db-6cc67df19a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa79b038-d8ac-45af-878a-be1dd166aaa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4210d3ae-de2f-4f30-90fd-9c20062b4090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066138fa-2b23-4d35-ae7a-3e33c203cfe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7152ee0-351a-44c0-9457-59b093582ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3a5763-2166-4073-8860-e12c670f727c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73e7901-2718-41c0-9a4b-c762fe032c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4860aeca-8186-4c66-b3b0-961f0762a69b",
   "metadata": {},
   "source": [
    "## generate response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1cf62c8-1a9b-4dc0-8017-2293202348c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"../results/inference_result\")\n",
    "eval_data_path = Path(\"../results/eval_result\")\n",
    "\n",
    "\n",
    "if not data_path.exists():\n",
    "    Path.mkdir(data_path)\n",
    "\n",
    "if not data_path.exists():\n",
    "    Path.mkdir(eval_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88a0e15b-2578-4776-b41e-563fec46c592",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "1it [00:06,  6.01s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "2it [00:11,  5.85s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "3it [00:16,  5.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "4it [00:22,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "5it [00:27,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "6it [00:32,  5.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "7it [00:35,  4.42s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "8it [00:43,  5.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "9it [00:47,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "10it [00:54,  5.41s/it]\n"
     ]
    }
   ],
   "source": [
    "df_test = df_qa[:10]\n",
    "llm_answer = []\n",
    "qe_answer = []\n",
    "\n",
    "for idx, row in tqdm(df_test.iterrows()):\n",
    "    query = row['question']\n",
    "    resp_llm = llm.complete(query)\n",
    "    resp_qe = query_engine_lm.query(query)\n",
    "    llm_answer.append(resp_llm)\n",
    "    qe_answer.append(resp_qe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76966d13-3f31-4d37-a39d-7d6211c6b6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.concat([df_test, df_test])\n",
    "df_eval['answer_llm'] = llm_answer + qe_answer\n",
    "df_eval['model'] = ['llm']*len(llm_answer) + ['qe']*len(qe_answer)\n",
    "df_eval.to_csv(f\"{data_path}/qa_inferenced.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "abb95f91-b3e4-47ff-9efc-d49b24aa4028",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (634 > 512). Running this sequence through the model will result in indexing errors\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "1it [00:06,  6.30s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "2it [00:10,  4.87s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "3it [00:14,  4.85s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "4it [00:20,  5.22s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "5it [00:24,  5.00s/it]\n"
     ]
    }
   ],
   "source": [
    "llm_answer = []\n",
    "qe_answer = []\n",
    "\n",
    "for idx, row in tqdm(df_qa_new_model.iterrows()):\n",
    "    query = row['question']\n",
    "    resp_llm = llm.complete(query)\n",
    "    resp_qe = query_engine_lm.query(query)\n",
    "    llm_answer.append(resp_llm)\n",
    "    qe_answer.append(resp_qe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba06dca-009a-4343-9555-1bc1699e8f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.concat([df_qa_new_model, df_qa_new_model])\n",
    "df_eval['answer_llm'] = llm_answer + qe_answer\n",
    "df_eval['model'] = ['llm']*len(llm_answer) + ['qe']*len(qe_answer)\n",
    "df_eval.to_csv(f\"{data_path}/qa_models_inferenced.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65758b2a-681b-49e2-9a85-698b646a974a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60597bb-d382-4cca-82b9-ebb0f5d3a55b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2164c3e-97cd-4802-ab4b-e8b1d943b63e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617f835e-1df2-4a8b-84cb-00582c5e73df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fcf54e-5d99-47ee-995c-d7914b94be28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04abd35-1a23-44f7-a511-a09a6e16d795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be403985-9290-4d34-86ff-f637e3b01fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f01b6b0-b7af-4bdc-b04a-2251ef41af52",
   "metadata": {},
   "source": [
    "## result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36822fbe-43ff-4080-83cb-41a89e9a276d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>qa_pairs</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>model</th>\n",
       "      <th>result</th>\n",
       "      <th>score</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fuzzy clustering (also referred to as soft clu...</td>\n",
       "      <td>What is fuzzy clustering and how does it diffe...</td>\n",
       "      <td>What is fuzzy clustering and how does it diffe...</td>\n",
       "      <td>Fuzzy clustering allows data points to belong ...</td>\n",
       "      <td>\\n\\nFuzzy clustering is a data analysis techni...</td>\n",
       "      <td>llm</td>\n",
       "      <td>query='What is fuzzy clustering and how does i...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>The generated answer correctly explains what f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>== Training ==\\nAn RNN using LSTM units can be...</td>\n",
       "      <td>What problem does the use of gradient descent ...</td>\n",
       "      <td>What problem does the use of gradient descent ...</td>\n",
       "      <td>Using gradient descent for standard RNNs can l...</td>\n",
       "      <td>\\n\\nGradient descent poses a problem for stand...</td>\n",
       "      <td>llm</td>\n",
       "      <td>query='What problem does the use of gradient d...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>The generated answer is relevant and mostly co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>What is the purpose of evaluating language mod...</td>\n",
       "      <td>What is the purpose of evaluating language mod...</td>\n",
       "      <td>Evaluating language models using perplexity he...</td>\n",
       "      <td>\\nPerplexity is a measure of how difficult it ...</td>\n",
       "      <td>llm</td>\n",
       "      <td>query='What is the purpose of evaluating langu...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>The generated answer is relevant to the user q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>== Definition ==\\nLet \\n  \\n    \\n      \\n    ...</td>\n",
       "      <td>What is a hidden Markov model?\\n    \\n[answer]...</td>\n",
       "      <td>What is a hidden Markov model?</td>\n",
       "      <td>A hidden Markov model consists of a pair of di...</td>\n",
       "      <td>\\nA hidden Markov model (HMM) is a statistical...</td>\n",
       "      <td>llm</td>\n",
       "      <td>query='What is a hidden Markov model?' context...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>The generated answer is relevant and mostly co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>== Inception Program ==\\nNvidia's Inception Pr...</td>\n",
       "      <td>What was the controversy surrounding Nvidia an...</td>\n",
       "      <td>What was the controversy surrounding Nvidia an...</td>\n",
       "      <td>Nvidia faced controversy when they decided to ...</td>\n",
       "      <td>\\n\\nHardware Unboxed was a video game review s...</td>\n",
       "      <td>llm</td>\n",
       "      <td>query='What was the controversy surrounding Nv...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The generated answer is not relevant to the us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>== Deep learning ==\\nThe previous section desc...</td>\n",
       "      <td>What is the key design desideratum for MoE in ...</td>\n",
       "      <td>What is the key design desideratum for MoE in ...</td>\n",
       "      <td>The key design desideratum for MoE in deep lea...</td>\n",
       "      <td>\\n\\nThe key design desideratum for MoE in deep...</td>\n",
       "      <td>llm</td>\n",
       "      <td>query='What is the key design desideratum for ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The generated answer is relevant to the user q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>In computing, the term text processing refers ...</td>\n",
       "      <td>What is text processing in computing?\\n\\n[answ...</td>\n",
       "      <td>What is text processing in computing?</td>\n",
       "      <td>Text processing in computing refers to automat...</td>\n",
       "      <td>\\nText processing in computing refers to the p...</td>\n",
       "      <td>llm</td>\n",
       "      <td>query='What is text processing in computing?' ...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>The generated answer is relevant and mostly co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>== Limitations ==\\nRLHF suffers from challenge...</td>\n",
       "      <td>What are some limitations of Reinforcement Lea...</td>\n",
       "      <td>What are some limitations of Reinforcement Lea...</td>\n",
       "      <td>RLHF faces challenges in gathering human feedb...</td>\n",
       "      <td>\\n1. Limited Feedback: RLHF relies on user fee...</td>\n",
       "      <td>llm</td>\n",
       "      <td>query='What are some limitations of Reinforcem...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>The generated answer is highly relevant to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>=== Training an autoencoder ===\\nAn autoencode...</td>\n",
       "      <td>What defines the task for judging the quality ...</td>\n",
       "      <td>What defines the task for judging the quality ...</td>\n",
       "      <td>The task for assessing the quality of an autoe...</td>\n",
       "      <td>\\nThe task for judging the quality of an autoe...</td>\n",
       "      <td>llm</td>\n",
       "      <td>query='What defines the task for judging the q...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>The generated answer is relevant to the user q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{\\displaystyle {\\begin{aligned}Q(\\theta \\mid \\...</td>\n",
       "      <td>What is the significance of the M step in the ...</td>\n",
       "      <td>What is the significance of the M step in the ...</td>\n",
       "      <td>The M step in the expectation maximization (EM...</td>\n",
       "      <td>\\n\\nThe M step in the context of expectation m...</td>\n",
       "      <td>llm</td>\n",
       "      <td>query='What is the significance of the M step ...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>The generated answer is relevant and mostly co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fuzzy clustering (also referred to as soft clu...</td>\n",
       "      <td>What is fuzzy clustering and how does it diffe...</td>\n",
       "      <td>What is fuzzy clustering and how does it diffe...</td>\n",
       "      <td>Fuzzy clustering allows data points to belong ...</td>\n",
       "      <td>\\nFuzzy clustering is a type of clustering tha...</td>\n",
       "      <td>qe</td>\n",
       "      <td>query='What is fuzzy clustering and how does i...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>The generated answer correctly explains what f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>== Training ==\\nAn RNN using LSTM units can be...</td>\n",
       "      <td>What problem does the use of gradient descent ...</td>\n",
       "      <td>What problem does the use of gradient descent ...</td>\n",
       "      <td>Using gradient descent for standard RNNs can l...</td>\n",
       "      <td>\\nGradient descent for standard RNNs has a pro...</td>\n",
       "      <td>qe</td>\n",
       "      <td>query='What problem does the use of gradient d...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>The generated answer is relevant and almost fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>What is the purpose of evaluating language mod...</td>\n",
       "      <td>What is the purpose of evaluating language mod...</td>\n",
       "      <td>Evaluating language models using perplexity he...</td>\n",
       "      <td>\\nThe purpose of evaluating language models us...</td>\n",
       "      <td>qe</td>\n",
       "      <td>query='What is the purpose of evaluating langu...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>The generated answer is relevant and mostly co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>== Definition ==\\nLet \\n  \\n    \\n      \\n    ...</td>\n",
       "      <td>What is a hidden Markov model?\\n    \\n[answer]...</td>\n",
       "      <td>What is a hidden Markov model?</td>\n",
       "      <td>A hidden Markov model consists of a pair of di...</td>\n",
       "      <td>A hidden Markov model (HMM) is a statistical ...</td>\n",
       "      <td>qe</td>\n",
       "      <td>query='What is a hidden Markov model?' context...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>The generated answer is relevant and mostly co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>== Inception Program ==\\nNvidia's Inception Pr...</td>\n",
       "      <td>What was the controversy surrounding Nvidia an...</td>\n",
       "      <td>What was the controversy surrounding Nvidia an...</td>\n",
       "      <td>Nvidia faced controversy when they decided to ...</td>\n",
       "      <td>\\nThe controversy surrounding Nvidia and Hardw...</td>\n",
       "      <td>qe</td>\n",
       "      <td>query='What was the controversy surrounding Nv...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>The generated answer is relevant and almost fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>== Deep learning ==\\nThe previous section desc...</td>\n",
       "      <td>What is the key design desideratum for MoE in ...</td>\n",
       "      <td>What is the key design desideratum for MoE in ...</td>\n",
       "      <td>The key design desideratum for MoE in deep lea...</td>\n",
       "      <td>\\nThe key design desideratum for MoE in deep l...</td>\n",
       "      <td>qe</td>\n",
       "      <td>query='What is the key design desideratum for ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>The generated answer is relevant to the user q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>In computing, the term text processing refers ...</td>\n",
       "      <td>What is text processing in computing?\\n\\n[answ...</td>\n",
       "      <td>What is text processing in computing?</td>\n",
       "      <td>Text processing in computing refers to automat...</td>\n",
       "      <td>Text processing in computing is the theory an...</td>\n",
       "      <td>qe</td>\n",
       "      <td>query='What is text processing in computing?' ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The generated answer is relevant and mostly co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>== Limitations ==\\nRLHF suffers from challenge...</td>\n",
       "      <td>What are some limitations of Reinforcement Lea...</td>\n",
       "      <td>What are some limitations of Reinforcement Lea...</td>\n",
       "      <td>RLHF faces challenges in gathering human feedb...</td>\n",
       "      <td>\\n1. Scalability and cost of human feedback\\n2...</td>\n",
       "      <td>qe</td>\n",
       "      <td>query='What are some limitations of Reinforcem...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>The generated answer is highly relevant to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>=== Training an autoencoder ===\\nAn autoencode...</td>\n",
       "      <td>What defines the task for judging the quality ...</td>\n",
       "      <td>What defines the task for judging the quality ...</td>\n",
       "      <td>The task for assessing the quality of an autoe...</td>\n",
       "      <td>\\nThe task for judging the quality of an autoe...</td>\n",
       "      <td>qe</td>\n",
       "      <td>query='What defines the task for judging the q...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>The generated answer is relevant and mostly co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{\\displaystyle {\\begin{aligned}Q(\\theta \\mid \\...</td>\n",
       "      <td>What is the significance of the M step in the ...</td>\n",
       "      <td>What is the significance of the M step in the ...</td>\n",
       "      <td>The M step in the expectation maximization (EM...</td>\n",
       "      <td>\\nThe M step in the context of expectation max...</td>\n",
       "      <td>qe</td>\n",
       "      <td>query='What is the significance of the M step ...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>The generated answer is relevant and mostly co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              context  \\\n",
       "0   Fuzzy clustering (also referred to as soft clu...   \n",
       "1   == Training ==\\nAn RNN using LSTM units can be...   \n",
       "2                                                 NaN   \n",
       "3   == Definition ==\\nLet \\n  \\n    \\n      \\n    ...   \n",
       "4   == Inception Program ==\\nNvidia's Inception Pr...   \n",
       "5   == Deep learning ==\\nThe previous section desc...   \n",
       "6   In computing, the term text processing refers ...   \n",
       "7   == Limitations ==\\nRLHF suffers from challenge...   \n",
       "8   === Training an autoencoder ===\\nAn autoencode...   \n",
       "9   {\\displaystyle {\\begin{aligned}Q(\\theta \\mid \\...   \n",
       "10  Fuzzy clustering (also referred to as soft clu...   \n",
       "11  == Training ==\\nAn RNN using LSTM units can be...   \n",
       "12                                                NaN   \n",
       "13  == Definition ==\\nLet \\n  \\n    \\n      \\n    ...   \n",
       "14  == Inception Program ==\\nNvidia's Inception Pr...   \n",
       "15  == Deep learning ==\\nThe previous section desc...   \n",
       "16  In computing, the term text processing refers ...   \n",
       "17  == Limitations ==\\nRLHF suffers from challenge...   \n",
       "18  === Training an autoencoder ===\\nAn autoencode...   \n",
       "19  {\\displaystyle {\\begin{aligned}Q(\\theta \\mid \\...   \n",
       "\n",
       "                                             qa_pairs  \\\n",
       "0   What is fuzzy clustering and how does it diffe...   \n",
       "1   What problem does the use of gradient descent ...   \n",
       "2   What is the purpose of evaluating language mod...   \n",
       "3   What is a hidden Markov model?\\n    \\n[answer]...   \n",
       "4   What was the controversy surrounding Nvidia an...   \n",
       "5   What is the key design desideratum for MoE in ...   \n",
       "6   What is text processing in computing?\\n\\n[answ...   \n",
       "7   What are some limitations of Reinforcement Lea...   \n",
       "8   What defines the task for judging the quality ...   \n",
       "9   What is the significance of the M step in the ...   \n",
       "10  What is fuzzy clustering and how does it diffe...   \n",
       "11  What problem does the use of gradient descent ...   \n",
       "12  What is the purpose of evaluating language mod...   \n",
       "13  What is a hidden Markov model?\\n    \\n[answer]...   \n",
       "14  What was the controversy surrounding Nvidia an...   \n",
       "15  What is the key design desideratum for MoE in ...   \n",
       "16  What is text processing in computing?\\n\\n[answ...   \n",
       "17  What are some limitations of Reinforcement Lea...   \n",
       "18  What defines the task for judging the quality ...   \n",
       "19  What is the significance of the M step in the ...   \n",
       "\n",
       "                                             question  \\\n",
       "0   What is fuzzy clustering and how does it diffe...   \n",
       "1   What problem does the use of gradient descent ...   \n",
       "2   What is the purpose of evaluating language mod...   \n",
       "3                      What is a hidden Markov model?   \n",
       "4   What was the controversy surrounding Nvidia an...   \n",
       "5   What is the key design desideratum for MoE in ...   \n",
       "6               What is text processing in computing?   \n",
       "7   What are some limitations of Reinforcement Lea...   \n",
       "8   What defines the task for judging the quality ...   \n",
       "9   What is the significance of the M step in the ...   \n",
       "10  What is fuzzy clustering and how does it diffe...   \n",
       "11  What problem does the use of gradient descent ...   \n",
       "12  What is the purpose of evaluating language mod...   \n",
       "13                     What is a hidden Markov model?   \n",
       "14  What was the controversy surrounding Nvidia an...   \n",
       "15  What is the key design desideratum for MoE in ...   \n",
       "16              What is text processing in computing?   \n",
       "17  What are some limitations of Reinforcement Lea...   \n",
       "18  What defines the task for judging the quality ...   \n",
       "19  What is the significance of the M step in the ...   \n",
       "\n",
       "                                               answer  \\\n",
       "0   Fuzzy clustering allows data points to belong ...   \n",
       "1   Using gradient descent for standard RNNs can l...   \n",
       "2   Evaluating language models using perplexity he...   \n",
       "3   A hidden Markov model consists of a pair of di...   \n",
       "4   Nvidia faced controversy when they decided to ...   \n",
       "5   The key design desideratum for MoE in deep lea...   \n",
       "6   Text processing in computing refers to automat...   \n",
       "7   RLHF faces challenges in gathering human feedb...   \n",
       "8   The task for assessing the quality of an autoe...   \n",
       "9   The M step in the expectation maximization (EM...   \n",
       "10  Fuzzy clustering allows data points to belong ...   \n",
       "11  Using gradient descent for standard RNNs can l...   \n",
       "12  Evaluating language models using perplexity he...   \n",
       "13  A hidden Markov model consists of a pair of di...   \n",
       "14  Nvidia faced controversy when they decided to ...   \n",
       "15  The key design desideratum for MoE in deep lea...   \n",
       "16  Text processing in computing refers to automat...   \n",
       "17  RLHF faces challenges in gathering human feedb...   \n",
       "18  The task for assessing the quality of an autoe...   \n",
       "19  The M step in the expectation maximization (EM...   \n",
       "\n",
       "                                           answer_llm model  \\\n",
       "0   \\n\\nFuzzy clustering is a data analysis techni...   llm   \n",
       "1   \\n\\nGradient descent poses a problem for stand...   llm   \n",
       "2   \\nPerplexity is a measure of how difficult it ...   llm   \n",
       "3   \\nA hidden Markov model (HMM) is a statistical...   llm   \n",
       "4   \\n\\nHardware Unboxed was a video game review s...   llm   \n",
       "5   \\n\\nThe key design desideratum for MoE in deep...   llm   \n",
       "6   \\nText processing in computing refers to the p...   llm   \n",
       "7   \\n1. Limited Feedback: RLHF relies on user fee...   llm   \n",
       "8   \\nThe task for judging the quality of an autoe...   llm   \n",
       "9   \\n\\nThe M step in the context of expectation m...   llm   \n",
       "10  \\nFuzzy clustering is a type of clustering tha...    qe   \n",
       "11  \\nGradient descent for standard RNNs has a pro...    qe   \n",
       "12  \\nThe purpose of evaluating language models us...    qe   \n",
       "13   A hidden Markov model (HMM) is a statistical ...    qe   \n",
       "14  \\nThe controversy surrounding Nvidia and Hardw...    qe   \n",
       "15  \\nThe key design desideratum for MoE in deep l...    qe   \n",
       "16   Text processing in computing is the theory an...    qe   \n",
       "17  \\n1. Scalability and cost of human feedback\\n2...    qe   \n",
       "18  \\nThe task for judging the quality of an autoe...    qe   \n",
       "19  \\nThe M step in the context of expectation max...    qe   \n",
       "\n",
       "                                               result  score  \\\n",
       "0   query='What is fuzzy clustering and how does i...    4.5   \n",
       "1   query='What problem does the use of gradient d...    4.5   \n",
       "2   query='What is the purpose of evaluating langu...    3.5   \n",
       "3   query='What is a hidden Markov model?' context...    4.5   \n",
       "4   query='What was the controversy surrounding Nv...    1.0   \n",
       "5   query='What is the key design desideratum for ...    2.0   \n",
       "6   query='What is text processing in computing?' ...    4.5   \n",
       "7   query='What are some limitations of Reinforcem...    4.5   \n",
       "8   query='What defines the task for judging the q...    3.5   \n",
       "9   query='What is the significance of the M step ...    4.5   \n",
       "10  query='What is fuzzy clustering and how does i...    4.5   \n",
       "11  query='What problem does the use of gradient d...    4.5   \n",
       "12  query='What is the purpose of evaluating langu...    4.5   \n",
       "13  query='What is a hidden Markov model?' context...    4.5   \n",
       "14  query='What was the controversy surrounding Nv...    4.5   \n",
       "15  query='What is the key design desideratum for ...    2.5   \n",
       "16  query='What is text processing in computing?' ...    4.0   \n",
       "17  query='What are some limitations of Reinforcem...    4.5   \n",
       "18  query='What defines the task for judging the q...    4.5   \n",
       "19  query='What is the significance of the M step ...    4.5   \n",
       "\n",
       "                                             feedback  \n",
       "0   The generated answer correctly explains what f...  \n",
       "1   The generated answer is relevant and mostly co...  \n",
       "2   The generated answer is relevant to the user q...  \n",
       "3   The generated answer is relevant and mostly co...  \n",
       "4   The generated answer is not relevant to the us...  \n",
       "5   The generated answer is relevant to the user q...  \n",
       "6   The generated answer is relevant and mostly co...  \n",
       "7   The generated answer is highly relevant to the...  \n",
       "8   The generated answer is relevant to the user q...  \n",
       "9   The generated answer is relevant and mostly co...  \n",
       "10  The generated answer correctly explains what f...  \n",
       "11  The generated answer is relevant and almost fu...  \n",
       "12  The generated answer is relevant and mostly co...  \n",
       "13  The generated answer is relevant and mostly co...  \n",
       "14  The generated answer is relevant and almost fu...  \n",
       "15  The generated answer is relevant to the user q...  \n",
       "16  The generated answer is relevant and mostly co...  \n",
       "17  The generated answer is highly relevant to the...  \n",
       "18  The generated answer is relevant and mostly co...  \n",
       "19  The generated answer is relevant and mostly co...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.read_csv(f\"{eval_data_path}/qa_inferenced_eval.csv\")\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43ff5d16-b958-4e98-ae52-3a6b96680ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qe</th>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score\n",
       "model       \n",
       "llm     3.70\n",
       "qe      4.25"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result[['model', 'score']].groupby('model').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff6534e2-fe89-42e3-92c4-6f328ef60802",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>context</th>\n",
       "      <th>qa_pairs</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>model</th>\n",
       "      <th>result</th>\n",
       "      <th>score</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Claude is a family of large language models de...</td>\n",
       "      <td>What is Claude 3?\\n    \\n    [answer]\\n    Cla...</td>\n",
       "      <td>What is Claude 3?</td>\n",
       "      <td>Claude 3 is a software application used for de...</td>\n",
       "      <td>\\n\\nClaude 3 is a French comedy film directed ...</td>\n",
       "      <td>llm</td>\n",
       "      <td>query='What is Claude 3?' contexts=None respon...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The generated answer is not relevant to the us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>== Technical specifications ==\\nThe first gene...</td>\n",
       "      <td>What is the latest version of Gemini? \\n    \\n...</td>\n",
       "      <td>What is the latest version of Gemini?</td>\n",
       "      <td>The latest version of Gemini is 1.5.</td>\n",
       "      <td>\\n\\nThe latest version of Gemini is 0.13.1.</td>\n",
       "      <td>llm</td>\n",
       "      <td>query='What is the latest version of Gemini?' ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The generated answer is relevant to the user q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>==== Mixtral 8x7B ====\\nMuch like Mistral's fi...</td>\n",
       "      <td>What is the key feature of Mixtral8x7B?\\n    \\...</td>\n",
       "      <td>What is the key feature of Mixtral8x7B?</td>\n",
       "      <td>Mixtral8x7B is known for its 7 billion paramet...</td>\n",
       "      <td>\\nThe key feature of Mixtral8x7B is its abilit...</td>\n",
       "      <td>llm</td>\n",
       "      <td>query='What is the key feature of Mixtral8x7B?...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The generated answer is not relevant to the us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>=== Fine-tuning ===\\nLlama 1 models are only a...</td>\n",
       "      <td>What is the purpose of Llama2?\\n\\n[answer]\\nLl...</td>\n",
       "      <td>What is the purpose of Llama2?</td>\n",
       "      <td>Llama2 is a language model designed to generat...</td>\n",
       "      <td>\\nLlama2 is a free and open-source software pr...</td>\n",
       "      <td>llm</td>\n",
       "      <td>query='What is the purpose of Llama2?' context...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The generated answer is not relevant to the us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Huawei PanGu, PanGu, PanGu-Σ or PanGu-π is a m...</td>\n",
       "      <td>What is PanGu? \\n    \\n[answer]\\nPanGu is a Ch...</td>\n",
       "      <td>What is PanGu?</td>\n",
       "      <td>PanGu is a Chinese natural language processing...</td>\n",
       "      <td>\\nPanGu is a popular Chinese herbal medicine, ...</td>\n",
       "      <td>llm</td>\n",
       "      <td>query='What is PanGu?' contexts=None response=...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The generated answer is not relevant to the us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Claude is a family of large language models de...</td>\n",
       "      <td>What is Claude 3?\\n    \\n    [answer]\\n    Cla...</td>\n",
       "      <td>What is Claude 3?</td>\n",
       "      <td>Claude 3 is a software application used for de...</td>\n",
       "      <td>\\nClaude 3 is a language model developed by An...</td>\n",
       "      <td>qe</td>\n",
       "      <td>query='What is Claude 3?' contexts=None respon...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The generated answer is not relevant to the us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>== Technical specifications ==\\nThe first gene...</td>\n",
       "      <td>What is the latest version of Gemini? \\n    \\n...</td>\n",
       "      <td>What is the latest version of Gemini?</td>\n",
       "      <td>The latest version of Gemini is 1.5.</td>\n",
       "      <td>\\nGemini 1.0 was announced on December 6, 2023...</td>\n",
       "      <td>qe</td>\n",
       "      <td>query='What is the latest version of Gemini?' ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The generated answer does not provide the info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>==== Mixtral 8x7B ====\\nMuch like Mistral's fi...</td>\n",
       "      <td>What is the key feature of Mixtral8x7B?\\n    \\...</td>\n",
       "      <td>What is the key feature of Mixtral8x7B?</td>\n",
       "      <td>Mixtral8x7B is known for its 7 billion paramet...</td>\n",
       "      <td>\\nThe key feature of Mixtral8x7B is its use of...</td>\n",
       "      <td>qe</td>\n",
       "      <td>query='What is the key feature of Mixtral8x7B?...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>The generated answer is relevant to the user q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>=== Fine-tuning ===\\nLlama 1 models are only a...</td>\n",
       "      <td>What is the purpose of Llama2?\\n\\n[answer]\\nLl...</td>\n",
       "      <td>What is the purpose of Llama2?</td>\n",
       "      <td>Llama2 is a language model designed to generat...</td>\n",
       "      <td>\\nLlama 2 is a chatbot and conversational agen...</td>\n",
       "      <td>qe</td>\n",
       "      <td>query='What is the purpose of Llama2?' context...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>The generated answer is relevant and mostly co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Huawei PanGu, PanGu, PanGu-Σ or PanGu-π is a m...</td>\n",
       "      <td>What is PanGu? \\n    \\n[answer]\\nPanGu is a Ch...</td>\n",
       "      <td>What is PanGu?</td>\n",
       "      <td>PanGu is a Chinese natural language processing...</td>\n",
       "      <td>\\nPanGu is a large learning language model dev...</td>\n",
       "      <td>qe</td>\n",
       "      <td>query='What is PanGu?' contexts=None response=...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>The generated answer is relevant and correct. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            context  \\\n",
       "0           0  Claude is a family of large language models de...   \n",
       "1           1  == Technical specifications ==\\nThe first gene...   \n",
       "2           2  ==== Mixtral 8x7B ====\\nMuch like Mistral's fi...   \n",
       "3           3  === Fine-tuning ===\\nLlama 1 models are only a...   \n",
       "4           4  Huawei PanGu, PanGu, PanGu-Σ or PanGu-π is a m...   \n",
       "5           5  Claude is a family of large language models de...   \n",
       "6           6  == Technical specifications ==\\nThe first gene...   \n",
       "7           7  ==== Mixtral 8x7B ====\\nMuch like Mistral's fi...   \n",
       "8           8  === Fine-tuning ===\\nLlama 1 models are only a...   \n",
       "9           9  Huawei PanGu, PanGu, PanGu-Σ or PanGu-π is a m...   \n",
       "\n",
       "                                            qa_pairs  \\\n",
       "0  What is Claude 3?\\n    \\n    [answer]\\n    Cla...   \n",
       "1  What is the latest version of Gemini? \\n    \\n...   \n",
       "2  What is the key feature of Mixtral8x7B?\\n    \\...   \n",
       "3  What is the purpose of Llama2?\\n\\n[answer]\\nLl...   \n",
       "4  What is PanGu? \\n    \\n[answer]\\nPanGu is a Ch...   \n",
       "5  What is Claude 3?\\n    \\n    [answer]\\n    Cla...   \n",
       "6  What is the latest version of Gemini? \\n    \\n...   \n",
       "7  What is the key feature of Mixtral8x7B?\\n    \\...   \n",
       "8  What is the purpose of Llama2?\\n\\n[answer]\\nLl...   \n",
       "9  What is PanGu? \\n    \\n[answer]\\nPanGu is a Ch...   \n",
       "\n",
       "                                  question  \\\n",
       "0                        What is Claude 3?   \n",
       "1    What is the latest version of Gemini?   \n",
       "2  What is the key feature of Mixtral8x7B?   \n",
       "3           What is the purpose of Llama2?   \n",
       "4                           What is PanGu?   \n",
       "5                        What is Claude 3?   \n",
       "6    What is the latest version of Gemini?   \n",
       "7  What is the key feature of Mixtral8x7B?   \n",
       "8           What is the purpose of Llama2?   \n",
       "9                           What is PanGu?   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Claude 3 is a software application used for de...   \n",
       "1               The latest version of Gemini is 1.5.   \n",
       "2  Mixtral8x7B is known for its 7 billion paramet...   \n",
       "3  Llama2 is a language model designed to generat...   \n",
       "4  PanGu is a Chinese natural language processing...   \n",
       "5  Claude 3 is a software application used for de...   \n",
       "6               The latest version of Gemini is 1.5.   \n",
       "7  Mixtral8x7B is known for its 7 billion paramet...   \n",
       "8  Llama2 is a language model designed to generat...   \n",
       "9  PanGu is a Chinese natural language processing...   \n",
       "\n",
       "                                          answer_llm model  \\\n",
       "0  \\n\\nClaude 3 is a French comedy film directed ...   llm   \n",
       "1        \\n\\nThe latest version of Gemini is 0.13.1.   llm   \n",
       "2  \\nThe key feature of Mixtral8x7B is its abilit...   llm   \n",
       "3  \\nLlama2 is a free and open-source software pr...   llm   \n",
       "4  \\nPanGu is a popular Chinese herbal medicine, ...   llm   \n",
       "5  \\nClaude 3 is a language model developed by An...    qe   \n",
       "6  \\nGemini 1.0 was announced on December 6, 2023...    qe   \n",
       "7  \\nThe key feature of Mixtral8x7B is its use of...    qe   \n",
       "8  \\nLlama 2 is a chatbot and conversational agen...    qe   \n",
       "9  \\nPanGu is a large learning language model dev...    qe   \n",
       "\n",
       "                                              result  score  \\\n",
       "0  query='What is Claude 3?' contexts=None respon...    1.0   \n",
       "1  query='What is the latest version of Gemini?' ...    2.0   \n",
       "2  query='What is the key feature of Mixtral8x7B?...    1.0   \n",
       "3  query='What is the purpose of Llama2?' context...    1.0   \n",
       "4  query='What is PanGu?' contexts=None response=...    1.0   \n",
       "5  query='What is Claude 3?' contexts=None respon...    1.0   \n",
       "6  query='What is the latest version of Gemini?' ...    1.0   \n",
       "7  query='What is the key feature of Mixtral8x7B?...    2.5   \n",
       "8  query='What is the purpose of Llama2?' context...    4.5   \n",
       "9  query='What is PanGu?' contexts=None response=...    4.5   \n",
       "\n",
       "                                            feedback  \n",
       "0  The generated answer is not relevant to the us...  \n",
       "1  The generated answer is relevant to the user q...  \n",
       "2  The generated answer is not relevant to the us...  \n",
       "3  The generated answer is not relevant to the us...  \n",
       "4  The generated answer is not relevant to the us...  \n",
       "5  The generated answer is not relevant to the us...  \n",
       "6  The generated answer does not provide the info...  \n",
       "7  The generated answer is relevant to the user q...  \n",
       "8  The generated answer is relevant and mostly co...  \n",
       "9  The generated answer is relevant and correct. ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_models = pd.read_csv(f\"{eval_data_path}/qa_models_inferenced_eval.csv\")\n",
    "df_result_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e039e0f5-707f-4313-9430-025195d1e974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qe</th>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score\n",
       "model       \n",
       "llm      1.2\n",
       "qe       2.7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_models[['model', 'score']].groupby('model').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9789f9-b545-42c3-96fa-bd1def5d624d",
   "metadata": {},
   "source": [
    "## results - finetuning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04dee751-e8dd-40b2-8b22-1b4dc4a14e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>finetune</th>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qe</th>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          score\n",
       "model          \n",
       "finetune   3.30\n",
       "llm        3.70\n",
       "qe         4.25"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_ft = pd.read_csv(f\"{eval_data_path}/qa_inferenced_ft_eval.csv\")\n",
    "df_result_all = pd.concat([df_result, df_result_ft])\n",
    "df_result_all[['model', 'score']].groupby('model').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "929acd56-ed99-4dd1-99dc-433cebdf98fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "==query==\n",
      "What is fuzzy clustering and how does it differ from hard clustering?\n",
      "==answer_llm==\n",
      "Fuzzy clustering is a clustering method that uses a fuzzy membership function to assign a cluster label to each data point. It differs from hard clustering in that it allows for multiple clusters and does not require the data points to be in a specific order. Fuzzy clustering is often used in scenarios where the data points are not ordered or have a high degree of uncertainty.\n",
      "==score==\n",
      "3.0\n",
      "==feedback==\n",
      "The generated answer is relevant to the user query, but it contains some inaccuracies. It correctly explains that fuzzy clustering assigns a cluster label to each data point using a fuzzy membership function, but it incorrectly states that fuzzy clustering allows for multiple clusters and does not require the data points to be in a specific order. The key difference between fuzzy and hard clustering is that in fuzzy clustering, data points can belong to multiple clusters with varying degrees of membership, while in hard clustering, each data point belongs to exactly one cluster.\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "==query==\n",
      "What problem does the use of gradient descent pose for standard RNNs and how does LSTM address this issue?\n",
      "==answer_llm==\n",
      "Gradient descent poses a problem for standard RNNs as it requires the calculation of the gradient of the loss function with respect to the weights of the network, which can be computationally expensive. LSTM addresses this issue by using a memory cell to store the output of the network, allowing the gradient to be calculated using the backpropagation algorithm. This allows LSTM to be more efficient and less prone to the issue of gradient vanishing.\n",
      "==score==\n",
      "4.0\n",
      "==feedback==\n",
      "The generated answer is relevant and mostly correct. It correctly identifies the problem of gradient vanishing in standard RNNs and how LSTM addresses it. However, it incorrectly states that the use of a memory cell in LSTM allows for the calculation of the gradient using the backpropagation algorithm, which is a common feature in all neural networks, not just LSTM. The main advantage of LSTM is its ability to maintain error within the cell and continuously feed it back through the gates until learning occurs, as stated in the reference answer.\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "==query==\n",
      "What is the purpose of evaluating language models using perplexity?\n",
      "==answer_llm==\n",
      "Evaluating language models using perplexity is a measure of how well they can predict the output of a given model, given a set of input sentences. It is calculated by taking the logarithm of the probability of the model's output given the input sentence, and then dividing it by the logarithm of the probability of the model's output given the correct input sentence. This measure is used to evaluate the performance of language models in predicting the output of a given sentence.\n",
      "==score==\n",
      "2.5\n",
      "==feedback==\n",
      "The generated answer is relevant to the user query as it talks about evaluating language models using perplexity. However, it contains mistakes in explaining how perplexity is calculated and its purpose. It does not mention the importance of perplexity in assessing the model's ability to predict unseen data and avoid overfitting, which is crucial information.\n",
      "\n",
      "\n",
      "\n",
      "3\n",
      "==query==\n",
      "What is a hidden Markov model?\n",
      "==answer_llm==\n",
      "A hidden Markov model is a statistical model that allows for the estimation of the probability of a sequence of events based on the observed sequence and a set of hidden states. It is a type of Markov model that allows for the estimation of the probability of a sequence of events based on the observed sequence and a set of hidden states.\n",
      "==score==\n",
      "4.0\n",
      "==feedback==\n",
      "The generated answer is relevant and mostly correct. It accurately describes a hidden Markov model as a statistical model that estimates the probability of a sequence of events based on observed sequences and hidden states. However, it is repetitive and does not mention the use of conditional probability or the wide application of the model in various fields, as mentioned in the reference answer.\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      "==query==\n",
      "What was the controversy surrounding Nvidia and Hardware Unboxed?\n",
      "==answer_llm==\n",
      "The controversy surrounding Nvidia and Hardware Unboxed centered around the company's decision to use a proprietary GPU architecture in its gaming console, the Shield, which was criticized for being incompatible with open-source software and not being able to run Linux-based games. The company later released a Linux-based console called Shield Ultimate, which was also criticized for being incompatible with open-source software.\n",
      "==score==\n",
      "1.0\n",
      "==feedback==\n",
      "The generated answer is not relevant to the user query. It discusses a different controversy involving Nvidia and does not mention Hardware Unboxed at all. The user query was specifically about the controversy involving Nvidia and Hardware Unboxed, not about Nvidia's proprietary GPU architecture or their gaming console.\n",
      "\n",
      "\n",
      "\n",
      "5\n",
      "==query==\n",
      "What is the key design desideratum for MoE in deep learning and how does it differ from classical MoE?\n",
      "==answer_llm==\n",
      "The key design desideratum for MoE in deep learning is to provide a method for training deep neural networks to learn the underlying structure of the data without requiring explicit feature extraction. This differs from classical MoE, which aims to learn the feature extraction process from the data, and requires explicit feature extraction for training. MoE in deep learning aims to learn the underlying structure of the data without explicit feature extraction, while classical MoE aims to learn the feature extraction process from the data.\n",
      "==score==\n",
      "2.0\n",
      "==feedback==\n",
      "The generated answer is relevant to the user query as it discusses the design desideratum for MoE in deep learning and how it differs from classical MoE. However, it contains mistakes. The key design desideratum for MoE in deep learning is not about learning the underlying structure of the data without requiring explicit feature extraction, but rather about reducing computing cost by only querying a small subset of experts for each query. This is a significant deviation from the correct information.\n",
      "\n",
      "\n",
      "\n",
      "6\n",
      "==query==\n",
      "What is text processing in computing?\n",
      "==answer_llm==\n",
      "Text processing in computing refers to the process of converting text data into a format suitable for analysis, such as text mining, natural language processing, and text analytics. It involves various tasks like tokenization, normalization, and stemming, among others.\n",
      "==score==\n",
      "4.0\n",
      "==feedback==\n",
      "The generated answer is relevant and mostly correct. It provides a good explanation of text processing in computing, but it focuses more on the analysis aspect and doesn't mention the use of computer commands to manipulate text files, which is included in the reference answer.\n",
      "\n",
      "\n",
      "\n",
      "7\n",
      "==query==\n",
      "What are some limitations of Reinforcement Learning from Human Feedback (RLHF)?\n",
      "==answer_llm==\n",
      "RLHF has limitations such as the need for a large amount of data to train the model, the potential for overfitting, and the difficulty in interpreting the results. Additionally, RLHF requires a human to provide feedback, which can be challenging in some cases.\n",
      "==score==\n",
      "3.5\n",
      "==feedback==\n",
      "The generated answer is relevant to the user query and mentions some of the limitations of RLHF, such as the need for large amounts of data, potential for overfitting, and the challenges in interpreting results. However, it lacks some details present in the reference answer, such as the risk of models learning to manipulate feedback processes and the variability in the quality and consistency of human feedback.\n",
      "\n",
      "\n",
      "\n",
      "8\n",
      "==query==\n",
      "What defines the task for judging the quality of an autoencoder?\n",
      "==answer_llm==\n",
      "The task for judging the quality of an autoencoder is to determine if the model has learned the underlying data distribution or if it has been trained to model the data distribution but with poor performance. This is achieved by evaluating the model's ability to reconstruct the input data, which is compared to the original data, and comparing the reconstruction error to the original error.\n",
      "==score==\n",
      "4.5\n",
      "==feedback==\n",
      "The generated answer is relevant and mostly correct. It accurately describes the process of judging the quality of an autoencoder by evaluating the model's ability to reconstruct the input data. However, it does not mention the use of a reference probability distribution or the use of mathematical optimization techniques like gradient descent, which were included in the reference answer.\n",
      "\n",
      "\n",
      "\n",
      "9\n",
      "==query==\n",
      "What is the significance of the M step in the context of expectation maximization (EM) algorithm?\n",
      "==answer_llm==\n",
      "The M step in the context of expectation maximization (EM) algorithm is the process of updating the parameters of the model based on the current estimates and the current values of the parameters. It involves computing the expected value of the log-likelihood function, which is the logarithm of the likelihood function, and then maximizing this expected value to update the parameters.\n",
      "==score==\n",
      "4.5\n",
      "==feedback==\n",
      "The generated answer is relevant and mostly correct. It accurately describes the M step in the EM algorithm as the process of updating the parameters of the model based on current estimates. However, it does not mention the quadratic form of the optimization problem, which is mentioned in the reference answer.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, row in df_result_ft.iterrows():\n",
    "    print(idx)\n",
    "    print(\"==query==\")\n",
    "    print(row['question'])\n",
    "    print(\"==answer_llm==\")\n",
    "    print(row['answer_llm'])\n",
    "    print(\"==score==\")\n",
    "    print(row['score'])   \n",
    "    print(\"==feedback==\")\n",
    "    print(row['feedback'])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bcb7adc-8d94-4bda-86b6-9bb8e94b5ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>finetune</th>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qe</th>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          score\n",
       "model          \n",
       "finetune    1.5\n",
       "llm         1.2\n",
       "qe          2.7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_models_ft = pd.read_csv(f\"{eval_data_path}/qa_models_inferenced_ft_eval.csv\")\n",
    "df_result_models_all = pd.concat([df_result_models, df_result_models_ft])\n",
    "df_result_models_all[['model', 'score']].groupby('model').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71d1c8c4-b58f-45c5-8616-d4fb1505b277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 finetune\n",
      "==query==\n",
      "What is Claude 3?\n",
      "==answer_llm==\n",
      "Claude 3 is a machine learning algorithm that uses a combination of supervised learning and reinforcement learning to train a model to predict the output of a system, such as a computer or a human, based on the input provided by the system. The algorithm is designed to learn the system's output by interacting with it and receiving feedback from the system. The algorithm is used to train models for various tasks such as image recognition, natural language processing, and speech recognition.\n",
      "==score==\n",
      "1.0\n",
      "==feedback==\n",
      "The generated answer is not relevant to the user query. The user asked about Claude 3, a software application used for design and analysis in the field of environmental engineering, but the generated answer describes it as a machine learning algorithm, which is incorrect.\n",
      "\n",
      "\n",
      "\n",
      "0 llm\n",
      "==query==\n",
      "What is Claude 3?\n",
      "==answer_llm==\n",
      "\n",
      "\n",
      "Claude 3 is a French comedy film directed by Claude Chabrol and starring Jean-Paul Belmondo, Simone Signoret, and Pierre Brasseur. It is based on the play of the same name by Georges Feydeau.\n",
      "==score==\n",
      "1.0\n",
      "==feedback==\n",
      "The generated answer is not relevant to the user query. The user asked about a software application, but the chatbot provided information about a French comedy film.\n",
      "\n",
      "\n",
      "\n",
      "5 qe\n",
      "==query==\n",
      "What is Claude 3?\n",
      "==answer_llm==\n",
      "\n",
      "Claude 3 is a language model developed by Anthropic that was released in March 4, 2024. It is an extension of Claude 2, which was released in July 11, 2023. Claude 3 is an improved version that doubles the context window to 1 million tokens, allowing it to handle more written material. It has been shown to perform meta-cognitive reasoning, such as realizing it is being tested during needle in a haystack evaluations.\n",
      "==score==\n",
      "1.0\n",
      "==feedback==\n",
      "The generated answer is not relevant to the user query. The user asked about a software application used in environmental engineering, but the generated answer discusses a language model developed by Anthropic.\n",
      "\n",
      "\n",
      "\n",
      "4 finetune\n",
      "==query==\n",
      "What is PanGu?\n",
      "==answer_llm==\n",
      "PanGu is a probabilistic graphical model that represents the joint distribution of a set of variables, allowing for the inference of variables based on their dependencies. It is a generalization of the Markov chain model, which is a special case of PanGu.\n",
      "==score==\n",
      "1.0\n",
      "==feedback==\n",
      "The generated answer is not relevant to the user query. The user asked about PanGu, a Chinese natural language processing model, but the generated answer describes it as a probabilistic graphical model, which is incorrect.\n",
      "\n",
      "\n",
      "\n",
      "4 llm\n",
      "==query==\n",
      "What is PanGu?\n",
      "==answer_llm==\n",
      "\n",
      "PanGu is a popular Chinese herbal medicine, also known as Pangolin, which has been used to treat various diseases, including arthritis, muscle pain, and neurological disorders.\n",
      "==score==\n",
      "1.0\n",
      "==feedback==\n",
      "The generated answer is not relevant to the user query. The user asked about PanGu, a Chinese natural language processing model, but the generated answer incorrectly describes it as a type of Chinese herbal medicine.\n",
      "\n",
      "\n",
      "\n",
      "9 qe\n",
      "==query==\n",
      "What is PanGu?\n",
      "==answer_llm==\n",
      "\n",
      "PanGu is a large learning language model developed by Huawei, featuring an architecture with 1.085 trillion parameters and named after Chinese mythology and folklore. It was announced in July 2023 and is a contender to other multimodal large language models.\n",
      "==score==\n",
      "4.5\n",
      "==feedback==\n",
      "The generated answer is relevant and correct. It provides more detailed information than the reference answer, including the developer, the number of parameters, and the context of its naming. However, it does not explicitly mention that it is a natural language processing model, which is a minor omission.\n",
      "\n",
      "\n",
      "\n",
      "2 finetune\n",
      "==query==\n",
      "What is the key feature of Mixtral8x7B?\n",
      "==answer_llm==\n",
      "The key feature of Mixtral8x7B is its ability to handle large datasets and complex models, making it suitable for handling large datasets and complex models in machine learning tasks.\n",
      "==score==\n",
      "2.5\n",
      "==feedback==\n",
      "The generated answer is relevant to the user query as it talks about Mixtral8x7B's capabilities. However, it does not mention the key feature of Mixtral8x7B, which is its 7 billion parameters, as stated in the reference answer. Therefore, it is not fully correct.\n",
      "\n",
      "\n",
      "\n",
      "2 llm\n",
      "==query==\n",
      "What is the key feature of Mixtral8x7B?\n",
      "==answer_llm==\n",
      "\n",
      "The key feature of Mixtral8x7B is its ability to provide high-quality, crystal-clear sound with deep bass and smooth highs, making it ideal for music lovers and audiophiles.\n",
      "==score==\n",
      "1.0\n",
      "==feedback==\n",
      "The generated answer is not relevant to the user query. It seems to be describing a sound system or audio device, not a language model like Mixtral8x7B.\n",
      "\n",
      "\n",
      "\n",
      "7 qe\n",
      "==query==\n",
      "What is the key feature of Mixtral8x7B?\n",
      "==answer_llm==\n",
      "\n",
      "The key feature of Mixtral8x7B is its use of a sparse mixture of experts architecture, which allows the model to have 8 distinct groups of \"experts\" with a total of 46.7B parameters, resulting in a 12.9B parameter speed and cost.\n",
      "==score==\n",
      "2.5\n",
      "==feedback==\n",
      "The generated answer is relevant to the user query as it discusses the key feature of Mixtral8x7B. However, it contains mistakes as it mentions the model having 46.7B parameters, which contradicts the reference answer that states the model has 7 billion parameters.\n",
      "\n",
      "\n",
      "\n",
      "1 finetune\n",
      "==query==\n",
      "What is the latest version of Gemini?\n",
      "==answer_llm==\n",
      "The latest version of Gemini is 0.9.1, released in June 2018. The main features of Gemini include a graphical user interface, a built-in editor, and a built-in database system. Gemini also includes a built-in search engine and a built-in data visualization tool. Gemini is available for free download and is open-source software.\n",
      "==score==\n",
      "2.0\n",
      "==feedback==\n",
      "The generated answer is relevant to the user query but it contains incorrect information. The latest version of Gemini according to the reference answer is 1.5, not 0.9.1.\n",
      "\n",
      "\n",
      "\n",
      "1 llm\n",
      "==query==\n",
      "What is the latest version of Gemini?\n",
      "==answer_llm==\n",
      "\n",
      "\n",
      "The latest version of Gemini is 0.13.1.\n",
      "==score==\n",
      "2.0\n",
      "==feedback==\n",
      "The generated answer is relevant to the user query but it is incorrect when compared to the reference answer.\n",
      "\n",
      "\n",
      "\n",
      "6 qe\n",
      "==query==\n",
      "What is the latest version of Gemini?\n",
      "==answer_llm==\n",
      "\n",
      "Gemini 1.0 was announced on December 6, 2023, and comprises three models: Gemini Ultra, Gemini Pro, and Gemini Nano. It is integrated into Bard, Pixel 8 Pro, Search, Ads, Chrome, Duet AI, and Workspace, and is available in English only.\n",
      "==score==\n",
      "1.0\n",
      "==feedback==\n",
      "The generated answer does not provide the information asked for in the user query, which is the latest version of Gemini. Instead, it provides information about Gemini 1.0 and its integration, which is not relevant to the query.\n",
      "\n",
      "\n",
      "\n",
      "3 finetune\n",
      "==query==\n",
      "What is the purpose of Llama2?\n",
      "==answer_llm==\n",
      "Llama2 is a library for the development of machine learning models in Python, providing a simple and efficient way to build and train models using the TensorFlow library. It offers a wide range of models, including linear regression, logistic regression, decision trees, and random forests, and supports various machine learning algorithms.\n",
      "==score==\n",
      "1.0\n",
      "==feedback==\n",
      "The generated answer is not relevant to the user query. The user asked about Llama2 as a language model, but the generated answer describes it as a library for machine learning models in Python, which is incorrect.\n",
      "\n",
      "\n",
      "\n",
      "3 llm\n",
      "==query==\n",
      "What is the purpose of Llama2?\n",
      "==answer_llm==\n",
      "\n",
      "Llama2 is a free and open-source software project designed to provide a simple and user-friendly interface for creating and managing virtual llamas. It allows users to easily create, customize, and manage their virtual llama herds, as well as monitor their health and performance.\n",
      "==score==\n",
      "1.0\n",
      "==feedback==\n",
      "The generated answer is not relevant to the user query. The user asked about a language model, but the generated answer discusses a software for managing virtual llamas.\n",
      "\n",
      "\n",
      "\n",
      "8 qe\n",
      "==query==\n",
      "What is the purpose of Llama2?\n",
      "==answer_llm==\n",
      "\n",
      "Llama 2 is a chatbot and conversational agent developed by Meta that aims to provide human-like interactions with a focus on natural language understanding, context-rich responses, and natural language generation. It is designed to handle various tasks such as text-based chat, virtual assistants, and conversational agents, with a focus on natural language understanding and generation.\n",
      "==score==\n",
      "4.5\n",
      "==feedback==\n",
      "The generated answer is relevant and mostly correct. It provides a detailed explanation of what Llama2 is and its purpose, although it doesn't match the reference answer exactly. The generated answer seems to be describing a more advanced or specific version of Llama2.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, row in df_result_models_all.sort_values(['question', 'model']).iterrows():\n",
    "    print(idx, row['model'])\n",
    "    print(\"==query==\")\n",
    "    print(row['question'])\n",
    "    print(\"==answer_llm==\")\n",
    "    print(row['answer_llm'])\n",
    "    print(\"==score==\")\n",
    "    print(row['score'])   \n",
    "    print(\"==feedback==\")\n",
    "    print(row['feedback'])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481b0def-b1c8-4a0f-b60e-3bab80106c77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5cdf89-8cd8-47c0-866d-473a99d03d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0e593c-63eb-42d5-b931-4a53d9d98390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed4a55d-8a85-49ad-bfb6-e73896de4728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a0c7d1-47af-4193-9b98-69dd2ed28a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15aa5e2-d7d5-47b6-9182-786ae75c91cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
